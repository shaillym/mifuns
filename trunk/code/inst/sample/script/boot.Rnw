\input{settings.sty}
\usepackage{Sweave}
\SweaveOpts{keep.source=true}
\SweaveOpts{eps=false} 
\begin{document}
\vspace*{2cm}
\begin{center}
{\Large MIfuns Sample Script}\\
\vspace{1.5cm}
{\Large Phase I Modeling}\\
~\\
\today\\
~\\
Tim Bergsma\\
\end{center}
\newpage

\section{Purpose}
This script picks up after model.Rnw to process bootstrap results.
\subsection{Summarize bootstrap models.}
<<more>>= 
#wait for bootstraps to finish
require(MIfuns,lib.loc='~/Rlibs')
  if(file.exists('../nonmem/1005.boot/log.csv')){
    boot <- read.csv('../nonmem/1005.boot/log.csv',as.is=TRUE)
}else{
    boot <- rlog(
	run=1:300,
	project='../nonmem/1005.boot',
	boot=TRUE,
	append=FALSE,
	tool='nm7'
    )
    write.csv(boot, '../nonmem/1005.boot/log.csv')
}
head(boot)
unique(boot$parameter)
text2decimal(unique(boot$parameter))
boot$X <- NULL
@
It looks like we have 14 estimated parameters.  We will map them to the
original control stream.
<<pars>>=
boot <- boot[!is.na(text2decimal(boot$parameter)),]
head(boot)
unique(boot$moment)
unique(boot$value[boot$moment=='prse'])
@
prse, and therefore moment, is noninformative for these bootstraps.
<<drop>>=
boot <- boot[boot$moment=='estimate',]
boot$moment <- NULL
unique(boot$tool)
boot$tool <- NULL
head(boot)
unique(boot$value[boot$parameter %in% c('OMEGA2.1','OMEGA3.1','OMEGA3.2')])
unique(boot$parameter[boot$value=='0'])
@
Off-diagonals (and only off-diagonals) are noninformative.
<<off>>=
boot <- boot[!boot$value=='0',]
any(is.na(as.numeric(boot$value)))
boot$value <- as.numeric(boot$value)
head(boot)
@
\subsection{Restrict data to 95 percentiles.}
We did 300 runs.  Min and max are strongly dependent on number of runs, since 
with an unbounded distribution, (almost) any value is possible with enough sampling.
We clip to the 95 percentiles, to give distributions that are somewhat more
scale independent.
<<clip>>=
boot <- inner(
	boot, 
	preserve='run',
	id.var='parameter',
	measure.var='value'
)
head(boot)
any(is.na(boot$value))
boot <- boot[!is.na(boot$value),]
@
\subsection{Recover parameter metadata from a specially-marked control stream.}
We want meaningful names for our parameters.  Harvest these from a reviewed control
stream.
<<ctl2xml>>=
stream <- readLines('../nonmem/ctl/1005.ctl')
tail(stream)
doc <- ctl2xml(stream)
doc
params <- unique(boot[,'parameter',drop=FALSE])
params$defs <- lookup(params$parameter,within=doc)
params$labels <- lookup(params$parameter,within=doc,as='label')
params
boot$parameter <- lookup(boot$parameter,within=doc,as='label')
head(boot)
@
\subsection{Create covariate plot.}
Now we make a covariate plot for clearance.  We will normalize clearance 
by its median (we also could have used the model estimate).  We need to take 
cuts of weight, since we can only really show categorically-constrained distributions.
Male effect is already categorical.  I.e, the reference individual has median
clearance, is female, and has median weight.
\subsubsection{Recover original covariates for guidance.}
<<covs>>=
covariates <- read.csv('../data/derived/phase1.csv',na.strings='.')
head(covariates)
with(covariates,constant(WEIGHT,within=ID))
covariates <- unique(covariates[,c('ID','WEIGHT')])
head(covariates)
covariates$WT <- as.numeric(covariates$WEIGHT)
wt <- median(covariates$WT)
wt
range(covariates$WT)
@
\subsubsection{Reproduce the control stream submodel for selective cuts of a continuous covariate.}
In the model we normalized by 70 kg, so that cut will have null effect.
Let's try 65, 75, and 85 kg. We have to make a separate column for each
cut, which is a bit of work. Basically, we make two more copies of our
weight effect columns, and raise our normalized cuts to those powers, 
effectively reproducing the submodel from the control stream.
<<cuts>>=
head(boot) 
unique(boot$parameter)
clearance <- boot[boot$parameter %in% c('CL/F','WT.CL','Male.CL'),]
head(clearance)
frozen <- data.frame(cast(clearance,run~parameter),check.names=FALSE)
head(frozen)
frozen$WT.CL65 <- (65/70)**frozen$WT.CL
frozen$WT.CL75 <- (75/70)**frozen$WT.CL
frozen$WT.CL85 <- (85/70)**frozen$WT.CL
@
\subsubsection{Normalize key parameter}
<<key>>=
cl <- median(boot$value[boot$parameter=='CL/F'])
cl
head(frozen)
frozen[['CL/F']] <- frozen[['CL/F']]/cl
head(frozen)
frozen$WT.CL <- NULL
molten <- melt(frozen,id.var='run',na.rm=TRUE)
head(molten)
@
\subsubsection{Plot.}
Now we plot.  We reverse the variable factor to give us top-down layout
of strips.
<<covplot,fig=TRUE>>=
levels(molten$variable)
molten$variable <- factor(molten$variable,levels=rev(levels(molten$variable)))
print(stripplot(variable~value,molten,panel=panel.covplot))
@
\subsubsection{Summarize}
We see that clearance is estimated with good precision.  Ignoring outliers, there 
is not much effect on clearance of being male, relative to female.  Increasing 
weight is associated with increasing clearance.  There is a 79 percent probability
that an 85 kg person will have at least 25 percent greater clearance than a 70 kg
person.
\section{Parameter Table}
<<params>>=
library(Hmisc)
tab <- partab(1005,'../nonmem',tool='nm7',as=c('label','latex','model','estimate','unit','prse','se'))
tab$estimate <- as.character(signif(as.numeric(tab$estimate),3))
tab$estimate <- ifelse(is.na(tab$unit),tab$estimate,paste(tab$estimate, tab$unit))
tab$unit <- NULL
tab$label <- ifelse(is.na(tab$latex),tab$label,paste(tab$label, ' (',tab$latex,')',sep=''))
tab$latex <- NULL
names(tab)[names(tab)=='label'] <- 'parameter'
tab$root <- signif(sqrt(exp(as.numeric(tab$estimate))-1),3)
tab$estimate <- ifelse(contains('Omega|sigma',tab$parameter),paste(tab$estimate,' (\\%CV=',tab$root*100,')',sep=''),tab$estimate)
tab$root <- NULL
#offdiag <- contains('2.1',tab$parameter)
#tab$estimate[offdiag] <- text2decimal(tab$estimate[offdiag])
#omegablock <- text2decimal(tab$estimate[contains('Omega..(1|2)',tab$parameter)])
#cor <- signif(half(cov2cor(as.matrix(as.halfmatrix(omegablock))))[[2]],3)
#tab$estimate[offdiag] <- paste(sep='',tab$estimate[offdiag],' (COR=',cor,')')
tab$model[is.na(tab$model)] <- ''
#boot <- rlog(1:300,project='../nonmem/1005.boot',tool='nm7',boot=TRUE)
boot <- read.csv('../nonmem/1005.boot/log.csv',as.is=TRUE)
boot <- boot[boot$moment=='estimate',]
boot <- data.frame(cast(boot,...~moment))
boot[] <- lapply(boot,as.character)
boot <- boot[contains('THETA|OMEGA|SIGMA',boot$parameter),c('parameter','estimate')]
boot$estimate <- as.numeric(boot$estimate)
boot <- data.frame(cast(boot,parameter~.,value='estimate',fun=function(x)list(lo=as.character(signif(quantile(x,probs=0.05),3)),hi=as.character(signif(quantile(x,probs=0.95),3)))))
boot$CI <- with(boot, paste(sep='','(',lo,',',hi,')'))
names(boot)[names(boot)=='parameter'] <- 'name'
tab <- stableMerge(tab,boot[,c('name','CI')])
tab$name <- NULL
tab$se <- NULL
@ 
<<results=tex,echo=FALSE>>=
latex(
	tab,
	file='',
	rowname=NULL,
	caption='Parameter Estimates from Population Pharmacokinetic Model Run 1005',
	caption.lot='Model 1005 Parameters',
	label='p1005',
	where='ht',
	table.env=FALSE
)
@
\end{document}
